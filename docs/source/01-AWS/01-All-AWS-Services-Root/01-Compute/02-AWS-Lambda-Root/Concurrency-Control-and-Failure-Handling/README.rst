Concurrency Control
==============================================================================


1. 我们要解决什么问题
------------------------------------------------------------------------------
在使用 Lambda 作为 Event Driven 的计算单元的时候, 经常会遇到流量波动的问题. 例如我们处理一个请求的时间在 5 - 10 秒之间. 而按照设计我们的系统只能支持同一时间有 3 个 Lambda workers 同时处理. 注意虽然 Lambda 是能自动扩容提高并发量的, 但是 Lambda 计算时候可能会依赖数据库等外部系统, 而外部系统可不是能自动扩容的, 万一我们同时发起了太多的请求, 可能会将上游系统弄崩溃. 当在 10 秒内突然来了 100 个请求, 我们不希望同时启动 100 个 Lambda workers, 而是将这 100 个请求放入一个队列, 然后一个个处理, 保持同时最多有 3 个并发.

以上描述只是描述了核心挑战, 除此之外还有很多其他的挑战, 例如:

- 如何保证每个请求被处理的顺序和请求发起的顺序是一致的? (这里会涉及到 Kafka 里的 partition 或者 Kinesis 里的 sharding).
- 如何保证重试的幂等性? 保证重试的时候不会因为重复执行而造成数据错误?
- 如何保证处理的原子性? 如何保证不会出现部分成功或部分失败的情况?
- 有些 request 本身就是有问题的, 不可能被成功处理, 如何保证这些 request 不会一直占用着 worker 的资源?
- 这些请求需不需要持久化? 需要永久保存还是只需要保存一段时间?
- 这些请求是同步的还是异步的?

本文将深入研究如何使用 Lambda 来实现以上需求.


2. 注意
------------------------------------------------------------------------------
这里我们来考虑 worker 的计算都发生在 Lambda 内部, 而不存在 Lambda 需要调用花长时间运行的外部服务的情况. 因为在这种情况下我们调度的目标就是那个外部服务, 而不是 Lambda 了.


设定 Reserved concurrency
------------------------------------------------------------------------------
默认情况下一个 AWS Account 下的所有 region 的所有 Lambda function 最多不能超过 1000 个并发 (也就是同时最多有 1000 个 Lambda function 正在运行. 但是为了保护外部系统不被高并发所击穿, 所以我们需要限定这个 Lambda function 不能超过 3 个并发. 从而将影响限定在 Lambda function 内部.

Reference:

- `Configuring reserved concurrency <https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html>`_


保证业务逻辑幂等性 (Idempotent) 和原子性 (Atomic)
------------------------------------------------------------------------------
当一个业务逻辑可能会失败时, 重试就是必须得. 为了防止重试给业务带来不好的影响, 我们需要保证业务逻辑的幂等性. 也就是说, 重复执行多次, 结果都是一样的. 例如给银行账户 + 100 的操作就不是幂等的, 而将银行账户的余额设置为 100 就是幂等的.

当一个业务逻辑造成的影响不止一个, 并且这些影响不是先后发生的. 我们就需要保证原子性. 我们不希望出现这些影响发生到一半的时候业务逻辑失败了, 导致有些影响发生了, 有些影响还没有发生. 所谓原子性就是要么所有的影响都没有发生, 要么所有的影响都发生了.

诚然, 很多时候我们是不可能完全做到幂等和原子的. 但是一般我们会有一些办法来尽量接近这一目标.

举例来说, 假如我们的业务逻辑就是给银行账户 + 100. 那么我们需要保证重试之前, 上一次尝试已经确认失败了. 由于上一次的操作通常需要 5 - 10 秒, 所以我们的重试间隔应该大于 10 秒.

又举例来说, 假如我们的业务逻辑会从 A 处读取数据, 然后写入很多个文件到 S3 bucket. 为了避免这个写入过程中出现部分失败的情况, 我们可以先将数据写入到位于 S3 上的 temp folder, 然后再用 copy_object 的命令将这些文件移动到位于 S3 上的正式的 folder. 因为你经过计算, 并且直接通过客户端往 S3 写字节流的 IO 是相对较慢的. 而 copy_object 则是位于 AWS 内网的传输, 甚至有的时候没有实际的数据传输, 而只是 metadata, 这样就可以保证最后写入到正式的 folder 的过程发生的比直接写入要快的多, 自然发生错误的概率也小的多. 由于 copy_object 是你完成了业务逻辑之后的最后一步, 所以业务逻辑中间发生的错误从最后 S3 的视角看是全部失败了. 从而使得不满足原子性的概率大大降低了.



实验设计
------------------------------------------------------------------------------
我们设计这样一个业务逻辑:

- 正常的业务逻辑会在 1 - 6 秒内完成.
- 有 30% 的概率会因为外部系统的网络抖动导致需要超过 6 秒.
- 有 20% 的概率会因为随机因素而出现错误, 重试几次后是会最终完成的.
- 还有 10% 的概率会收到错误的请求而导致永远不可能成功.

.. literalinclude:: ./lambda_function.py
   :language: python
   :linenos:



- Lambda function name: ``lambda-concurrency-control-test-worker``
- Dynamodb table name: ``lambda-concurrency-control-test``
- SQS dead letter queue name: ``lambda-concurrency-control-test``
